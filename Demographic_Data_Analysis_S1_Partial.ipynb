{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Demographic Data Analysis\n",
    "## Milestone 1: Help Level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:35:46.690685Z",
     "start_time": "2023-09-05T20:35:46.391476Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the Pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the csv files with the Pandas function [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).   \n",
    "Check the following parameters : sep, names, header, and usecols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education file: \"education.csv\"\n",
    "The file contains the following columns:  \n",
    "\n",
    "```Column  | Description\n",
    "--------| --------------------------------\n",
    "1°       | name of the state         \n",
    "2°       | % high school graduate or higher  \n",
    "3°       | high School rank  \n",
    "4°      | % bachelor degree or higher  \n",
    "5°      | bachelor degree rank  \n",
    "6°      | % advanced degree or higher  \n",
    "7°      | advanced degree rank\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:35:48.511109Z",
     "start_time": "2023-09-05T20:35:48.466051Z"
    }
   },
   "outputs": [],
   "source": [
    "# There is no mention of column names. We should better make a first read of the file to see what we find in it.\n",
    "# Load and inspect the file education.csv\n",
    "education_csv_name = 'work/csv/education.csv'\n",
    "# df = pd.read_csv('%s' % education_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:35:50.843898Z",
     "start_time": "2023-09-05T20:35:50.825229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            State HSGradPer  HSRank BADegPer  BARank AdvDegPer  AdvRank\n",
      "0         Montana     93.0%     1.0    30.7%    21.0     10.1%     33.0\n",
      "1   New Hampshire     92.8%     2.0    36.0%     9.0     13.8%     10.0\n",
      "2       Minnesota     92.8%     3.0    34.8%    11.0     11.8%     18.0\n",
      "3         Wyoming     92.8%     4.0    26.7%    41.0      9.3%     39.0\n",
      "4          Alaska     92.4%     5.0    29.0%    28.0     10.4%     29.0\n",
      "                    State HSGradPer BADegPer AdvDegPer\n",
      "0                 Montana     93.0%    30.7%     10.1%\n",
      "1           New Hampshire     92.8%    36.0%     13.8%\n",
      "2               Minnesota     92.8%    34.8%     11.8%\n",
      "3                 Wyoming     92.8%    26.7%      9.3%\n",
      "4                  Alaska     92.4%    29.0%     10.4%\n",
      "5            North Dakota     92.3%    28.9%      7.8%\n",
      "6                 Vermont     92.3%    36.8%     15.0%\n",
      "7                   Maine     92.1%    30.3%     10.9%\n",
      "8                    Iowa     91.8%    27.7%      9.0%\n",
      "9                    Utah     91.8%    32.5%     11.0%\n",
      "10              Wisconsin     91.7%    29.0%      9.9%\n",
      "11                 Hawaii     91.6%    32.0%     10.8%\n",
      "12           South Dakota     91.4%    27.8%      8.3%\n",
      "13               Colorado     91.1%    39.4%     14.6%\n",
      "14               Nebraska     90.9%    30.6%     10.2%\n",
      "15             Washington     90.8%    34.5%     12.7%\n",
      "16                 Kansas     90.5%    32.3%     11.7%\n",
      "17   District of Columbia     90.3%    56.6%     32.8%\n",
      "18          Massachusetts     90.3%    42.1%     18.7%\n",
      "19                  Idaho     90.2%    26.8%      8.5%\n",
      "20               Michigan     90.2%    28.1%     11.0%\n",
      "21            Connecticut     90.2%    38.4%     17.0%\n",
      "22                 Oregon     76.7%    32.3%     12.2%\n",
      "23           Pennsylvania     89.9%    30.1%     11.8%\n",
      "24               Maryland     89.8%    39.0%     18.0%\n",
      "25                   Ohio     89.8%    27.2%     10.2%\n",
      "26               Delaware     89.3%    31.0%     12.9%\n",
      "27               Missouri     89.2%    28.2%     10.7%\n",
      "28             New Jersey     89.2%    38.1%     14.7%\n",
      "29               Virginia     89.0%    37.6%     16.1%\n",
      "30               Illinois     88.6%    33.4%     13.0%\n",
      "31                Indiana     88.3%    25.3%      9.2%\n",
      "32                Florida     87.6%    28.5%     10.3%\n",
      "33               Oklahoma     87.5%    24.8%      8.3%\n",
      "34           Rhode Island     87.3%    33.0%     13.1%\n",
      "35          United States     87.3%    30.9%     11.8%\n",
      "36         North Carolina     86.9%    29.9%     10.6%\n",
      "37         South Carolina     86.5%    27.0%      9.8%\n",
      "38              Tennessee     86.5%    26.1%      9.6%\n",
      "39                Georgia     86.3%    29.9%     11.4%\n",
      "40               New York     86.1%    35.3%     15.4%\n",
      "41          West Virginia     85.9%    19.9%      7.9%\n",
      "42                 Nevada     85.8%    23.7%      8.1%\n",
      "43               Arkansas     85.6%    22.0%      7.9%\n",
      "44                Alabama     85.3%    24.5%      9.1%\n",
      "45               Kentucky     85.2%    23.2%      9.6%\n",
      "46             New Mexico     85.0%    26.9%     11.8%\n",
      "47              Louisiana     84.3%    23.4%      8.1%\n",
      "48            Mississippi     83.4%    21.3%      8.0%\n",
      "49                  Texas     82.8%    28.7%      9.9%\n",
      "50             California     82.5%    32.6%     12.2%\n",
      "51                Arizona     82.1%    28.4%     10.7%\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect the file education.csv \n",
    "# You can use the following columns names: 'State','HSGradPer','HSRank','BADegPer','BARank','AdvDegPer','AdvRank'\n",
    "# Ignore the rank columns or delete them after loading\n",
    "\n",
    "# Read the CSV file with custom column names\n",
    "# Skip the initial rows that are not part of the data\n",
    "df = pd.read_csv('%s' % education_csv_name, skiprows=2,\n",
    "                 delimiter=';',\n",
    "                 header=None,\n",
    "                 names=['State','HSGradPer','HSRank','BADegPer','BARank','AdvDegPer','AdvRank'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# # Drop the columns corresponding to ranks\n",
    "df.drop(['HSRank', 'BARank', 'AdvRank'], axis=1, inplace=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame to inspect the data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:59:10.120790Z",
     "start_time": "2023-09-05T20:59:10.027983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=52, step=1)\n",
      "Index(['State', 'HSGradPer', 'BADegPer', 'AdvDegPer'], dtype='object')\n",
      "State        object\n",
      "HSGradPer    object\n",
      "BADegPer     object\n",
      "AdvDegPer    object\n",
      "dtype: object\n",
      "No duplicate values found in the State column.\n",
      "No NaN values found in the State column.\n",
      "All values in the State column are strings.\n",
      "Index([' Montana', ' New Hampshire', ' Minnesota', ' Wyoming', ' Alaska',\n",
      "       ' North Dakota', ' Vermont', ' Maine', ' Iowa', ' Utah', ' Wisconsin',\n",
      "       ' Hawaii', ' South Dakota', ' Colorado', ' Nebraska', ' Washington',\n",
      "       ' Kansas', ' District of Columbia', ' Massachusetts', ' Idaho',\n",
      "       ' Michigan', ' Connecticut', ' Oregon', ' Pennsylvania', ' Maryland',\n",
      "       ' Ohio', ' Delaware', ' Missouri', ' New Jersey', ' Virginia',\n",
      "       ' Illinois', ' Indiana', ' Florida', ' Oklahoma', ' Rhode Island',\n",
      "       ' United States', ' North Carolina', ' South Carolina', ' Tennessee',\n",
      "       ' Georgia', ' New York', ' West Virginia', ' Nevada', ' Arkansas',\n",
      "       ' Alabama', ' Kentucky', ' New Mexico', ' Louisiana', ' Mississippi',\n",
      "       ' Texas', ' California', ' Arizona'],\n",
      "      dtype='object', name='State')\n",
      "Index(['HSGradPer', 'BADegPer', 'AdvDegPer'], dtype='object')\n",
      "HSGradPer    object\n",
      "BADegPer     object\n",
      "AdvDegPer    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# We want to use the column *State* as index. Lets's run some checks first.\n",
    "# Check that there are no extraneous values in the column State. If you find some, clean them.\n",
    "print(df.index)\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for duplicate values\n",
    "if df['State'].duplicated().any():\n",
    "    print(\"Duplicate values found in the State column:\")\n",
    "    print(df[df['State'].duplicated(keep=False)].sort_values(by='State'))\n",
    "else:\n",
    "    print(\"No duplicate values found in the State column.\")\n",
    "\n",
    "# Check for Missing or NaN Values\n",
    "if df['State'].isna().any():\n",
    "    print(\"NaN values found in the State column:\")\n",
    "    print(df[df['State'].isna()])\n",
    "else:\n",
    "    print(\"No NaN values found in the State column.\")\n",
    "\n",
    "non_strings = df[df['State'].apply(lambda x: not isinstance(x, str))]\n",
    "if not non_strings.empty:\n",
    "    print(\"Non-string values found in the State column:\")\n",
    "    print(non_strings)\n",
    "else:\n",
    "    print(\"All values in the State column are strings.\")\n",
    "\n",
    "# Set the index to 'State'\n",
    "df.set_index('State', inplace=True)\n",
    "\n",
    "print(df.index)\n",
    "print(df.columns)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a list comprehension to return all states in the column States that have extraneous characters. You can apply the Python method [isalpha](https://docs.python.org/3/library/stdtypes.html) to a string to check whether all characters in it are alphabetic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:59:32.019842Z",
     "start_time": "2023-09-05T20:59:31.904756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Montana', 'New_Hampshire', 'Minnesota', 'Wyoming', 'Alaska',\n",
      "       'North_Dakota', 'Vermont', 'Maine', 'Iowa', 'Utah', 'Wisconsin',\n",
      "       'Hawaii', 'South_Dakota', 'Colorado', 'Nebraska', 'Washington',\n",
      "       'Kansas', 'District_of_Columbia', 'Massachusetts', 'Idaho', 'Michigan',\n",
      "       'Connecticut', 'Oregon', 'Pennsylvania', 'Maryland', 'Ohio', 'Delaware',\n",
      "       'Missouri', 'New_Jersey', 'Virginia', 'Illinois', 'Indiana', 'Florida',\n",
      "       'Oklahoma', 'Rhode_Island', 'United_States', 'North_Carolina',\n",
      "       'South_Carolina', 'Tennessee', 'Georgia', 'New_York', 'West_Virginia',\n",
      "       'Nevada', 'Arkansas', 'Alabama', 'Kentucky', 'New_Mexico', 'Louisiana',\n",
      "       'Mississippi', 'Texas', 'California', 'Arizona'],\n",
      "      dtype='object', name='State')\n",
      "Are index values unique? True\n"
     ]
    }
   ],
   "source": [
    "# In the column State replace the whitespaces with underscores\n",
    "\n",
    "# Strip leading and trailing whitespaces from the index\n",
    "df.index = df.index.str.strip()\n",
    "\n",
    "#Replace all remaining whitespaces with underscores\n",
    "df.index = df.index.str.replace(' ', '_')\n",
    "\n",
    "# Show the modified index\n",
    "print(df.index)\n",
    "\n",
    "# Check if index values are unique\n",
    "are_indexes_unique = df.index.is_unique\n",
    "\n",
    "# Print the result\n",
    "print(\"Are index values unique?\", are_indexes_unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the Series method [str.replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html?highlight=str%20replace#pandas.Series.str.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:00:01.920640Z",
     "start_time": "2023-09-05T21:00:01.909918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     HSGradPer BADegPer AdvDegPer\n",
      "State                                            \n",
      "Montana                  93.0%    30.7%     10.1%\n",
      "New_Hampshire            92.8%    36.0%     13.8%\n",
      "Minnesota                92.8%    34.8%     11.8%\n",
      "Wyoming                  92.8%    26.7%      9.3%\n",
      "Alaska                   92.4%    29.0%     10.4%\n",
      "North_Dakota             92.3%    28.9%      7.8%\n",
      "Vermont                  92.3%    36.8%     15.0%\n",
      "Maine                    92.1%    30.3%     10.9%\n",
      "Iowa                     91.8%    27.7%      9.0%\n",
      "Utah                     91.8%    32.5%     11.0%\n",
      "Wisconsin                91.7%    29.0%      9.9%\n",
      "Hawaii                   91.6%    32.0%     10.8%\n",
      "South_Dakota             91.4%    27.8%      8.3%\n",
      "Colorado                 91.1%    39.4%     14.6%\n",
      "Nebraska                 90.9%    30.6%     10.2%\n",
      "Washington               90.8%    34.5%     12.7%\n",
      "Kansas                   90.5%    32.3%     11.7%\n",
      "District_of_Columbia     90.3%    56.6%     32.8%\n",
      "Massachusetts            90.3%    42.1%     18.7%\n",
      "Idaho                    90.2%    26.8%      8.5%\n",
      "Michigan                 90.2%    28.1%     11.0%\n",
      "Connecticut              90.2%    38.4%     17.0%\n",
      "Oregon                   76.7%    32.3%     12.2%\n",
      "Pennsylvania             89.9%    30.1%     11.8%\n",
      "Maryland                 89.8%    39.0%     18.0%\n",
      "Ohio                     89.8%    27.2%     10.2%\n",
      "Delaware                 89.3%    31.0%     12.9%\n",
      "Missouri                 89.2%    28.2%     10.7%\n",
      "New_Jersey               89.2%    38.1%     14.7%\n",
      "Virginia                 89.0%    37.6%     16.1%\n",
      "Illinois                 88.6%    33.4%     13.0%\n",
      "Indiana                  88.3%    25.3%      9.2%\n",
      "Florida                  87.6%    28.5%     10.3%\n",
      "Oklahoma                 87.5%    24.8%      8.3%\n",
      "Rhode_Island             87.3%    33.0%     13.1%\n",
      "North_Carolina           86.9%    29.9%     10.6%\n",
      "South_Carolina           86.5%    27.0%      9.8%\n",
      "Tennessee                86.5%    26.1%      9.6%\n",
      "Georgia                  86.3%    29.9%     11.4%\n",
      "New_York                 86.1%    35.3%     15.4%\n",
      "West_Virginia            85.9%    19.9%      7.9%\n",
      "Nevada                   85.8%    23.7%      8.1%\n",
      "Arkansas                 85.6%    22.0%      7.9%\n",
      "Alabama                  85.3%    24.5%      9.1%\n",
      "Kentucky                 85.2%    23.2%      9.6%\n",
      "New_Mexico               85.0%    26.9%     11.8%\n",
      "Louisiana                84.3%    23.4%      8.1%\n",
      "Mississippi              83.4%    21.3%      8.0%\n",
      "Texas                    82.8%    28.7%      9.9%\n",
      "California               82.5%    32.6%     12.2%\n",
      "Arizona                  82.1%    28.4%     10.7%\n"
     ]
    }
   ],
   "source": [
    "# Get rid of the summary row \"United_States\"\n",
    "\n",
    "# Remove the row with index 'United_States'\n",
    "# df.drop('United_States', inplace=True)\n",
    "df.drop('United_States', inplace=True, errors='ignore')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the DataFrame method [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:00:26.759116Z",
     "start_time": "2023-09-05T21:00:26.662112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is only one row for each state.\n"
     ]
    }
   ],
   "source": [
    "# Make a last check that there is only one row for each state\n",
    "# Count the number of unique index values (states)\n",
    "num_unique_states = df.index.nunique()\n",
    "\n",
    "# Count the total number of rows in the DataFrame\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "# Check if each state has only one corresponding row\n",
    "if num_unique_states == total_rows:\n",
    "    print(\"There is only one row for each state.\")\n",
    "else:\n",
    "    print(\"Some states appear more than once.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:00:37.906735Z",
     "start_time": "2023-09-05T21:00:37.876543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     HSGradPer BADegPer AdvDegPer\n",
      "State                                            \n",
      "Alabama                  85.3%    24.5%      9.1%\n",
      "Alaska                   92.4%    29.0%     10.4%\n",
      "Arizona                  82.1%    28.4%     10.7%\n",
      "Arkansas                 85.6%    22.0%      7.9%\n",
      "California               82.5%    32.6%     12.2%\n",
      "Colorado                 91.1%    39.4%     14.6%\n",
      "Connecticut              90.2%    38.4%     17.0%\n",
      "Delaware                 89.3%    31.0%     12.9%\n",
      "District_of_Columbia     90.3%    56.6%     32.8%\n",
      "Florida                  87.6%    28.5%     10.3%\n",
      "Georgia                  86.3%    29.9%     11.4%\n",
      "Hawaii                   91.6%    32.0%     10.8%\n",
      "Idaho                    90.2%    26.8%      8.5%\n",
      "Illinois                 88.6%    33.4%     13.0%\n",
      "Indiana                  88.3%    25.3%      9.2%\n",
      "Iowa                     91.8%    27.7%      9.0%\n",
      "Kansas                   90.5%    32.3%     11.7%\n",
      "Kentucky                 85.2%    23.2%      9.6%\n",
      "Louisiana                84.3%    23.4%      8.1%\n",
      "Maine                    92.1%    30.3%     10.9%\n",
      "Maryland                 89.8%    39.0%     18.0%\n",
      "Massachusetts            90.3%    42.1%     18.7%\n",
      "Michigan                 90.2%    28.1%     11.0%\n",
      "Minnesota                92.8%    34.8%     11.8%\n",
      "Mississippi              83.4%    21.3%      8.0%\n",
      "Missouri                 89.2%    28.2%     10.7%\n",
      "Montana                  93.0%    30.7%     10.1%\n",
      "Nebraska                 90.9%    30.6%     10.2%\n",
      "Nevada                   85.8%    23.7%      8.1%\n",
      "New_Hampshire            92.8%    36.0%     13.8%\n",
      "New_Jersey               89.2%    38.1%     14.7%\n",
      "New_Mexico               85.0%    26.9%     11.8%\n",
      "New_York                 86.1%    35.3%     15.4%\n",
      "North_Carolina           86.9%    29.9%     10.6%\n",
      "North_Dakota             92.3%    28.9%      7.8%\n",
      "Ohio                     89.8%    27.2%     10.2%\n",
      "Oklahoma                 87.5%    24.8%      8.3%\n",
      "Oregon                   76.7%    32.3%     12.2%\n",
      "Pennsylvania             89.9%    30.1%     11.8%\n",
      "Rhode_Island             87.3%    33.0%     13.1%\n",
      "South_Carolina           86.5%    27.0%      9.8%\n",
      "South_Dakota             91.4%    27.8%      8.3%\n",
      "Tennessee                86.5%    26.1%      9.6%\n",
      "Texas                    82.8%    28.7%      9.9%\n",
      "Utah                     91.8%    32.5%     11.0%\n",
      "Vermont                  92.3%    36.8%     15.0%\n",
      "Virginia                 89.0%    37.6%     16.1%\n",
      "Washington               90.8%    34.5%     12.7%\n",
      "West_Virginia            85.9%    19.9%      7.9%\n",
      "Wisconsin                91.7%    29.0%      9.9%\n",
      "Wyoming                  92.8%    26.7%      9.3%\n"
     ]
    }
   ],
   "source": [
    "# Set the column State as the index\n",
    "# Order the dataframe according to the index\n",
    "# Inspect the dataframe\n",
    "\n",
    "# Set the 'State' column as the index\n",
    "# df.set_index('State', inplace=True)\n",
    "\n",
    "# Sort the DataFrame by the index (State)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame to inspect the data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there is only one row for each state and then set *State* as the index of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:00:57.749305Z",
     "start_time": "2023-09-05T21:00:57.712806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSGradPer    object\n",
      "BADegPer     object\n",
      "AdvDegPer    object\n",
      "dtype: object\n",
      "['85.3%' '92.4%' '82.1%' '85.6%' '82.5%' '91.1%' '90.2%' '89.3%' '90.3%'\n",
      " '87.6%' '86.3%' '91.6%' '88.6%' '88.3%' '91.8%' '90.5%' '85.2%' '84.3%'\n",
      " '92.1%' '89.8%' '92.8%' '83.4%' '89.2%' '93.0%' '90.9%' '85.8%' '85.0%'\n",
      " '86.1%' '86.9%' '92.3%' '87.5%' '76.7%' '89.9%' '87.3%' '86.5%' '91.4%'\n",
      " '82.8%' '89.0%' '90.8%' '85.9%' '91.7%']\n",
      "['24.5%' '29.0%' '28.4%' '22.0%' '32.6%' '39.4%' '38.4%' '31.0%' '56.6%'\n",
      " '28.5%' '29.9%' '32.0%' '26.8%' '33.4%' '25.3%' '27.7%' '32.3%' '23.2%'\n",
      " '23.4%' '30.3%' '39.0%' '42.1%' '28.1%' '34.8%' '21.3%' '28.2%' '30.7%'\n",
      " '30.6%' '23.7%' '36.0%' '38.1%' '26.9%' '35.3%' '28.9%' '27.2%' '24.8%'\n",
      " '30.1%' '33.0%' '27.0%' '27.8%' '26.1%' '28.7%' '32.5%' '36.8%' '37.6%'\n",
      " '34.5%' '19.9%' '26.7%']\n",
      "['9.1%' '10.4%' '10.7%' '7.9%' '12.2%' '14.6%' '17.0%' '12.9%' '32.8%'\n",
      " '10.3%' '11.4%' '10.8%' '8.5%' '13.0%' '9.2%' '9.0%' '11.7%' '9.6%'\n",
      " '8.1%' '10.9%' '18.0%' '18.7%' '11.0%' '11.8%' '8.0%' '10.1%' '10.2%'\n",
      " '13.8%' '14.7%' '15.4%' '10.6%' '7.8%' '8.3%' '13.1%' '9.8%' '9.9%'\n",
      " '15.0%' '16.1%' '12.7%' '9.3%']\n",
      "HSGradPer    0\n",
      "BADegPer     0\n",
      "AdvDegPer    0\n",
      "dtype: int64\n",
      "HSGradPer    float64\n",
      "BADegPer     float64\n",
      "AdvDegPer    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check that all the numerical column were loaded as a number\n",
    "# If that's not the case, find out why, correct it, and cast the columns as numbers\n",
    "print(df.dtypes)\n",
    "\n",
    "print(df['HSGradPer'].unique())\n",
    "print(df['BADegPer'].unique())\n",
    "print(df['AdvDegPer'].unique())\n",
    "\n",
    "df['HSGradPer'] = df['HSGradPer'].str.replace('%', '')\n",
    "df['BADegPer'] = df['BADegPer'].str.replace('%', '')\n",
    "df['AdvDegPer'] = df['AdvDegPer'].str.replace('%', '')\n",
    "\n",
    "df['HSGradPer'] = pd.to_numeric(df['HSGradPer'], errors='coerce')\n",
    "df['BADegPer'] = pd.to_numeric(df['BADegPer'], errors='coerce')\n",
    "df['AdvDegPer'] = pd.to_numeric(df['AdvDegPer'], errors='coerce')\n",
    "\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:01:34.464491Z",
     "start_time": "2023-09-05T21:01:34.452260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      HSGradPer  BADegPer  AdvDegPer\n",
      "State                                               \n",
      "Alabama                    85.3      24.5        9.1\n",
      "Alaska                     92.4      29.0       10.4\n",
      "Arizona                    82.1      28.4       10.7\n",
      "Arkansas                   85.6      22.0        7.9\n",
      "California                 82.5      32.6       12.2\n",
      "Colorado                   91.1      39.4       14.6\n",
      "Connecticut                90.2      38.4       17.0\n",
      "Delaware                   89.3      31.0       12.9\n",
      "District_of_Columbia       90.3      56.6       32.8\n",
      "Florida                    87.6      28.5       10.3\n",
      "Georgia                    86.3      29.9       11.4\n",
      "Hawaii                     91.6      32.0       10.8\n",
      "Idaho                      90.2      26.8        8.5\n",
      "Illinois                   88.6      33.4       13.0\n",
      "Indiana                    88.3      25.3        9.2\n",
      "Iowa                       91.8      27.7        9.0\n",
      "Kansas                     90.5      32.3       11.7\n",
      "Kentucky                   85.2      23.2        9.6\n",
      "Louisiana                  84.3      23.4        8.1\n",
      "Maine                      92.1      30.3       10.9\n",
      "Maryland                   89.8      39.0       18.0\n",
      "Massachusetts              90.3      42.1       18.7\n",
      "Michigan                   90.2      28.1       11.0\n",
      "Minnesota                  92.8      34.8       11.8\n",
      "Mississippi                83.4      21.3        8.0\n",
      "Missouri                   89.2      28.2       10.7\n",
      "Montana                    93.0      30.7       10.1\n",
      "Nebraska                   90.9      30.6       10.2\n",
      "Nevada                     85.8      23.7        8.1\n",
      "New_Hampshire              92.8      36.0       13.8\n",
      "New_Jersey                 89.2      38.1       14.7\n",
      "New_Mexico                 85.0      26.9       11.8\n",
      "New_York                   86.1      35.3       15.4\n",
      "North_Carolina             86.9      29.9       10.6\n",
      "North_Dakota               92.3      28.9        7.8\n",
      "Ohio                       89.8      27.2       10.2\n",
      "Oklahoma                   87.5      24.8        8.3\n",
      "Oregon                     76.7      32.3       12.2\n",
      "Pennsylvania               89.9      30.1       11.8\n",
      "Rhode_Island               87.3      33.0       13.1\n",
      "South_Carolina             86.5      27.0        9.8\n",
      "South_Dakota               91.4      27.8        8.3\n",
      "Tennessee                  86.5      26.1        9.6\n",
      "Texas                      82.8      28.7        9.9\n",
      "Utah                       91.8      32.5       11.0\n",
      "Vermont                    92.3      36.8       15.0\n",
      "Virginia                   89.0      37.6       16.1\n",
      "Washington                 90.8      34.5       12.7\n",
      "West_Virginia              85.9      19.9        7.9\n",
      "Wisconsin                  91.7      29.0        9.9\n",
      "Wyoming                    92.8      26.7        9.3\n"
     ]
    }
   ],
   "source": [
    "# Make a last inspection of the dataframe edu\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Life Expectancy: \"life_expectancy.csv\"\n",
    "The file contains the following columns  \n",
    "\n",
    "```\n",
    "Column        | Description\n",
    "--------------| --------------------------------\n",
    "State         | name of the state  \n",
    "LifeExp2018   | life expectancy (2017)   \n",
    "LifeExp2010   | life expectancy (2010)\n",
    "MaleLifeExp   | male life expectancy\n",
    "FemLifeExp    | female life expectancy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the file life_expectancy.csv and make a first inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll follow the same steps for the file life_expectancy\n",
    "# Since you will have to repeat these steps for the other files, we are going to define a function to clean a dataset\n",
    "def set_state_as_index(df):\n",
    "    # clean the column 'State', eliminating extraneous whitespaces\n",
    "    \n",
    "    # replace the middle whitespaces with underscore\n",
    "\n",
    "    # check that there are no duplicates in the column 'State'\n",
    "    \n",
    "    # set the 'State' column as the index of the dataframe and sort by the index \n",
    "    \n",
    "    # if there is a summary row \"United States\", drop it\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function set_state_as_index on life_exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets's check which numeric columns contain something else than digits or a dot.   \n",
    "We are going to use regular expressions to check if the elements of the dataframe contain numbers (digits with or without a dot).  \n",
    "If you want to review regular expression, see the link we provided in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that uses regular expresions to check if a string contains only digits with or without a dot\n",
    "import re\n",
    "def check_digit_or_dot(x):\n",
    "    return ...\n",
    "# create a boolean dataframe that is the result of applying the function check_digit_or_dot to all the elements of life_exp\n",
    "\n",
    "# inspect the rows of the boolean dataframe to see if there are any False values\n",
    "\n",
    "# print the rows of life_exp where there is at least one value that's not a number\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coerce the columns to be numeric\n",
    "\n",
    "\n",
    "# check if all the columns are numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the whole dataframe life_exp to see if all is ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime file: \"crime.csv\"\n",
    "\n",
    "The file contains the following columns:\n",
    "\n",
    "```\n",
    "Column   |  Description\n",
    "---------| --------------------------------\n",
    "1°       |  name of the state                              \n",
    "2°       |  population (total inhabitants) (2015)                   \n",
    "3°       |  murders and non-negligent manslaughter (total deaths) (2015)\n",
    "4°       |  murders (total deaths) (2015)\n",
    "5°       |  gun murders (total deaths) (2015)\n",
    "6°       |  gun ownership (%) (2013)\n",
    "7°       |  murders and non-negligent manslaughter rate (per 100,000) (2015)\n",
    "8°       |  murder rate (per 100,000) \n",
    "9°       |  gun murder rate (per 100,000)\n",
    "```\n",
    "\n",
    "\n",
    "Follow the same procedure as with the other files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area file: \"area.csv\"\n",
    "\n",
    "The file contains the following columns:    \n",
    "\n",
    "```\n",
    "Column    |  Description\n",
    "----------| --------------------------------\n",
    "State     |  name of the state                              \n",
    "TotalRank |  total area rank  \n",
    "TotalSqMi |  total area in SqMi\n",
    "TotalKmQ  |  total area in KmQ\n",
    "LandRank  |  land area rank\n",
    "LandSqMi  |  land area in SqMi \n",
    "LandKmQ   |  land area in KmQ\n",
    "LandPer   |  land area percentage \n",
    "WaterRank |  water area rank\n",
    "WaterSqMi |  water area in SqMi\n",
    "WaterKmQ  |  water area in KmQ\n",
    "WaterPer  |  water area percentage\n",
    "```\n",
    "\n",
    "Follow the same procedure as the other files\n",
    "Do not load the rank columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income file: \"income.xls\"\n",
    "\n",
    "For the file income we have an excel file: 'income.xlsx'. It contains the following columns:  \n",
    "\n",
    "```\n",
    "Column                                  |  Description    \n",
    "--------------------------------------- | --------------------------------   \n",
    "Rank                                    |  Rank for income in 2017   \n",
    "State                                   |  name of the State    \n",
    "Income2017                              |  median household  income in 2017   \n",
    "Income2016                              |  median household  income in 2016  \n",
    "...                                     |  ...  \n",
    "Income2007                              |  median household  income in 2007\n",
    "```\n",
    "\n",
    "Follow the same procedure as with the other files  \n",
    "Since this is an Excel file you'll need the Pandas function [read_excel](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)  \n",
    "Do not load the rank column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region file: \"region.txt\"\n",
    "The file 'region.txt' file contains the following columns:  \n",
    "\n",
    "```\n",
    "Column     |  Description\n",
    "---------- | --------------------------------\n",
    "Name      |  name of the state \n",
    "Abb        |  abbreviation of the name of the state\n",
    "Region     |  the region that each state belong to (Northeast, South, North Central, West)\n",
    "Division   |  state division (New England, Middle Atlantic, South Atlantic, East South Central, West South Central, East North Central, West North Central, Mountain, and Pacific)\n",
    "```\n",
    "\n",
    "Follow the same procedure as the other files  \n",
    "You can load it with the Pandas function [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)   \n",
    "Check what column separator was used.   \n",
    "Pay attention to the Division Column. There appear to be some inconsistencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Report\n",
    "\n",
    "We loaded four csv data files, an excel file, and a text file. The first five data files were acquired from the following internet sources (Wikipedia):   \n",
    "* edu.csv : [List of U.S. states and territories by educational attainment](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_educational_attainment)\n",
    "* crime.csv: [Gun violence in the United States by state](https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state)\n",
    "* area.csv: [List of U.S. states and territories by area](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_area)\n",
    "* life_expectancy.csv: [List of U.S. states and territories by life expectancy](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_life_expectancy)\n",
    "The income file was provided in Excel format  \n",
    "* income.xlsx: Household income in the United States (https://en.wikipedia.org/wiki/Household_income_in_the_United_States)\n",
    "The region text data file was obtained from R package ‘datasets’ (state.x77)  \n",
    "* region.txt \n",
    "\n",
    "#### Problems encountered:\n",
    "** TO TO **\n",
    "List the problems you encountered and the solution you took\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part , you'll examine the \"surface\" properties of the data. \n",
    "Check the number of rows of each dataframe.\n",
    "You can use the DataFrame property [shape](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html#pandas.DataFrame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description Report\n",
    "\n",
    "We acquired the following dataframes. All the dataframes have as index the State column.\n",
    "\n",
    "###### edu\n",
    "** TO DO **\n",
    "number of rows\n",
    "\n",
    "```\n",
    "Column    |  Type   | Description\n",
    "----------|---------|-------------------------\n",
    "State     |  object | name of the state         \n",
    "HSGradPer | float64 | % high school graduate or higher  \n",
    "BADegPer  | float64 | % bachelor degree or higher  \n",
    "AdvDegPer | float64 | % advanced degree or higher  \n",
    "```\n",
    "\n",
    "###### life_exp\n",
    "** TO DO **\n",
    "number of rows \n",
    "\n",
    "```\n",
    "Column      |  Type   | Description\n",
    "------------|---------|-------------------------\n",
    "State       |  object | name of the state         \n",
    "LifeExp2018 | float64 | life expectancy (2017)   \n",
    "LifeExp2010 | float64 | life expectancy (2010)   \n",
    "MaleLifeExp | float64 | male life expectancy  \n",
    "FemLifeExp  | float64 | female life expectancy\n",
    "```\n",
    "\n",
    "###### crime\n",
    "** TO DO **\n",
    "number of rows \n",
    "\n",
    "```\n",
    "Column       |  Type   | Description\n",
    "-------------|---------|-------------------------\n",
    "State        |  object | name of the state           \n",
    "PopTot       |   int64 | population (total inhabitants) (2015) \n",
    "MurderNMTot  |   int64 | murders and non-negligent manslaughter (total deaths) (2015)\n",
    "MurderTot    | float64 | murders (total deaths) (2015) \n",
    "GunMurderTot | float64 | gun murders (total deaths) (2015)\n",
    "GunOwnerPer  | float64 | gun ownership (%) (2013) \n",
    "MurderNMRate | float64 | murders and non-negligent manslaughter rate (per 100,000) (2015) \n",
    "MurderRate   | float64 | murder rate (per 100,000)\n",
    "GunMurderRate| float64 | gun murder rate (per 100,000)\n",
    "```\n",
    "\n",
    "###### area\n",
    "** TO DO **\n",
    "number of rows\n",
    "\n",
    "```\n",
    "Column    |  Type   | Description\n",
    "----------|---------|-------------------------\n",
    "State     |  object | name of the state           \n",
    "TotalSqMi | float64 |  total area in SqMi\n",
    "TotalKmQ  |   int64 |  total area in KmQ\n",
    "LandSqMi  | float64 |  land area in SqMi \n",
    "LandKmQ   |   int64 |  land area in KmQ\n",
    "LandPer   | float64 |  land area percentage \n",
    "WaterSqMi | float64 |  water area in SqMi\n",
    "WaterKmQ  |   int64 |  water area in KmQ\n",
    "WaterPer  | float64 |  water area percentage\n",
    "```\n",
    "\n",
    "###### income\n",
    "** TO DO **\n",
    "number of rows rows\n",
    "\n",
    "```\n",
    "Column     |  Type   | Description\n",
    "-----------|---------|-------------------------\n",
    "State      |  object | name of the state           \n",
    "Income2017 |   int64 | median household income in 2017\n",
    "Income2016 |   int64 | median household income in 2016\n",
    "Income2015 |   int64 | median household income in 2015\n",
    "Income2014 |   int64 | median household income in 2014\n",
    "Income2013 |   int64 | median household income in 2013\n",
    "Income2012 |   int64 | median household income in 2012\n",
    "Income2011 |   int64 | median household income in 2012\n",
    "Income2010 |   int64 | median household income in 2010\n",
    "Income2009 |   int64 | median household income in 2009\n",
    "Income2008 |   int64 | median household income in 2008\n",
    "Income2007 |   int64 | median household income in 2007\n",
    "```\n",
    "\n",
    "###### region\n",
    "** TO DO **\n",
    "number of row\n",
    "\n",
    "```\n",
    "Column     |  Type   | Description\n",
    "-----------|---------|-------------------------\n",
    "State      |  object | name of the state    \n",
    "Abb        |  object | abbreviation of the name of the state\n",
    "Region     |  object | the region that each state belongs to (Northeast, South, North Central, West)          \n",
    "Division   |  object | state divisions (New England, Middle Atlantic, South Atlantic, East South Central, West South Central, East North Central, West North Central, Mountain, and Pacific)           \n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you’ll examine if the data is complete. Check if you have all the cases you need (in this case, all the US states) and if there are missing values.\n",
    "\n",
    "In the U.S. there are 50 states, the federal district 'District of Columbia' and 5 inhabited territories: 'Puerto Rico', 'American Samoa', 'Guam', 'Northern Mariana Islands', and 'U.S. Virgin Islands’.\n",
    "\n",
    "Check if all the files you loaded contain the fifty states and if there are differences, investigate where these differences come from. You can use the index of the DataFrame region as a guide.\n",
    "\n",
    "Then check if there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a variable state_names with the states in the index of region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the other DataFrames, check if they contain a state that's not in state_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the dataframes have missing values.   \n",
    "You can use the DataFrame method [isnull](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html?highlight=isnull#pandas.DataFrame.isnull)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Report\n",
    "\n",
    "In the U.S. there are fifty states, the federal district 'District of Columbia' and five inhabited territories: 'Puerto Rico', 'American Samoa', 'Guam', 'Northern Mariana Islands', and 'U.S. Virgin Islands'.\n",
    "\n",
    "** TO DO **       \n",
    "Explain your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframes for the next milestone.\n",
    "You can use the DataFrame method [to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html?highlight=to_csv#pandas.DataFrame.to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
