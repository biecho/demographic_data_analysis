{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Demographic Data Analysis\n",
    "## Milestone 1: Help Level 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:35:46.690685Z",
     "start_time": "2023-09-05T20:35:46.391476Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the Pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the csv files with the Pandas function [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html).   \n",
    "Check the following parameters : sep, names, header, and usecols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education file: \"education.csv\"\n",
    "The file contains the following columns:  \n",
    "\n",
    "```Column  | Description\n",
    "--------| --------------------------------\n",
    "1°       | name of the state         \n",
    "2°       | % high school graduate or higher  \n",
    "3°       | high School rank  \n",
    "4°      | % bachelor degree or higher  \n",
    "5°      | bachelor degree rank  \n",
    "6°      | % advanced degree or higher  \n",
    "7°      | advanced degree rank\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:35:48.511109Z",
     "start_time": "2023-09-05T20:35:48.466051Z"
    }
   },
   "outputs": [],
   "source": [
    "# There is no mention of column names. We should better make a first read of the file to see what we find in it.\n",
    "# Load and inspect the file education.csv\n",
    "education_csv_name = 'work/csv/education.csv'\n",
    "# df = pd.read_csv('%s' % education_csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:35:50.843898Z",
     "start_time": "2023-09-05T20:35:50.825229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            State HSGradPer  HSRank BADegPer  BARank AdvDegPer  AdvRank\n",
      "0         Montana     93.0%     1.0    30.7%    21.0     10.1%     33.0\n",
      "1   New Hampshire     92.8%     2.0    36.0%     9.0     13.8%     10.0\n",
      "2       Minnesota     92.8%     3.0    34.8%    11.0     11.8%     18.0\n",
      "3         Wyoming     92.8%     4.0    26.7%    41.0      9.3%     39.0\n",
      "4          Alaska     92.4%     5.0    29.0%    28.0     10.4%     29.0\n",
      "                    State HSGradPer BADegPer AdvDegPer\n",
      "0                 Montana     93.0%    30.7%     10.1%\n",
      "1           New Hampshire     92.8%    36.0%     13.8%\n",
      "2               Minnesota     92.8%    34.8%     11.8%\n",
      "3                 Wyoming     92.8%    26.7%      9.3%\n",
      "4                  Alaska     92.4%    29.0%     10.4%\n",
      "5            North Dakota     92.3%    28.9%      7.8%\n",
      "6                 Vermont     92.3%    36.8%     15.0%\n",
      "7                   Maine     92.1%    30.3%     10.9%\n",
      "8                    Iowa     91.8%    27.7%      9.0%\n",
      "9                    Utah     91.8%    32.5%     11.0%\n",
      "10              Wisconsin     91.7%    29.0%      9.9%\n",
      "11                 Hawaii     91.6%    32.0%     10.8%\n",
      "12           South Dakota     91.4%    27.8%      8.3%\n",
      "13               Colorado     91.1%    39.4%     14.6%\n",
      "14               Nebraska     90.9%    30.6%     10.2%\n",
      "15             Washington     90.8%    34.5%     12.7%\n",
      "16                 Kansas     90.5%    32.3%     11.7%\n",
      "17   District of Columbia     90.3%    56.6%     32.8%\n",
      "18          Massachusetts     90.3%    42.1%     18.7%\n",
      "19                  Idaho     90.2%    26.8%      8.5%\n",
      "20               Michigan     90.2%    28.1%     11.0%\n",
      "21            Connecticut     90.2%    38.4%     17.0%\n",
      "22                 Oregon     76.7%    32.3%     12.2%\n",
      "23           Pennsylvania     89.9%    30.1%     11.8%\n",
      "24               Maryland     89.8%    39.0%     18.0%\n",
      "25                   Ohio     89.8%    27.2%     10.2%\n",
      "26               Delaware     89.3%    31.0%     12.9%\n",
      "27               Missouri     89.2%    28.2%     10.7%\n",
      "28             New Jersey     89.2%    38.1%     14.7%\n",
      "29               Virginia     89.0%    37.6%     16.1%\n",
      "30               Illinois     88.6%    33.4%     13.0%\n",
      "31                Indiana     88.3%    25.3%      9.2%\n",
      "32                Florida     87.6%    28.5%     10.3%\n",
      "33               Oklahoma     87.5%    24.8%      8.3%\n",
      "34           Rhode Island     87.3%    33.0%     13.1%\n",
      "35          United States     87.3%    30.9%     11.8%\n",
      "36         North Carolina     86.9%    29.9%     10.6%\n",
      "37         South Carolina     86.5%    27.0%      9.8%\n",
      "38              Tennessee     86.5%    26.1%      9.6%\n",
      "39                Georgia     86.3%    29.9%     11.4%\n",
      "40               New York     86.1%    35.3%     15.4%\n",
      "41          West Virginia     85.9%    19.9%      7.9%\n",
      "42                 Nevada     85.8%    23.7%      8.1%\n",
      "43               Arkansas     85.6%    22.0%      7.9%\n",
      "44                Alabama     85.3%    24.5%      9.1%\n",
      "45               Kentucky     85.2%    23.2%      9.6%\n",
      "46             New Mexico     85.0%    26.9%     11.8%\n",
      "47              Louisiana     84.3%    23.4%      8.1%\n",
      "48            Mississippi     83.4%    21.3%      8.0%\n",
      "49                  Texas     82.8%    28.7%      9.9%\n",
      "50             California     82.5%    32.6%     12.2%\n",
      "51                Arizona     82.1%    28.4%     10.7%\n"
     ]
    }
   ],
   "source": [
    "# Load and inspect the file education.csv \n",
    "# You can use the following columns names: 'State','HSGradPer','HSRank','BADegPer','BARank','AdvDegPer','AdvRank'\n",
    "# Ignore the rank columns or delete them after loading\n",
    "\n",
    "# Read the CSV file with custom column names\n",
    "# Skip the initial rows that are not part of the data\n",
    "df = pd.read_csv('%s' % education_csv_name, skiprows=2,\n",
    "                 delimiter=';',\n",
    "                 header=None,\n",
    "                 names=['State','HSGradPer','HSRank','BADegPer','BARank','AdvDegPer','AdvRank'])\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# # Drop the columns corresponding to ranks\n",
    "df.drop(['HSRank', 'BARank', 'AdvRank'], axis=1, inplace=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame to inspect the data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:59:10.120790Z",
     "start_time": "2023-09-05T20:59:10.027983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=52, step=1)\n",
      "Index(['State', 'HSGradPer', 'BADegPer', 'AdvDegPer'], dtype='object')\n",
      "State        object\n",
      "HSGradPer    object\n",
      "BADegPer     object\n",
      "AdvDegPer    object\n",
      "dtype: object\n",
      "No duplicate values found in the State column.\n",
      "No NaN values found in the State column.\n",
      "All values in the State column are strings.\n",
      "Index([' Montana', ' New Hampshire', ' Minnesota', ' Wyoming', ' Alaska',\n",
      "       ' North Dakota', ' Vermont', ' Maine', ' Iowa', ' Utah', ' Wisconsin',\n",
      "       ' Hawaii', ' South Dakota', ' Colorado', ' Nebraska', ' Washington',\n",
      "       ' Kansas', ' District of Columbia', ' Massachusetts', ' Idaho',\n",
      "       ' Michigan', ' Connecticut', ' Oregon', ' Pennsylvania', ' Maryland',\n",
      "       ' Ohio', ' Delaware', ' Missouri', ' New Jersey', ' Virginia',\n",
      "       ' Illinois', ' Indiana', ' Florida', ' Oklahoma', ' Rhode Island',\n",
      "       ' United States', ' North Carolina', ' South Carolina', ' Tennessee',\n",
      "       ' Georgia', ' New York', ' West Virginia', ' Nevada', ' Arkansas',\n",
      "       ' Alabama', ' Kentucky', ' New Mexico', ' Louisiana', ' Mississippi',\n",
      "       ' Texas', ' California', ' Arizona'],\n",
      "      dtype='object', name='State')\n",
      "Index(['HSGradPer', 'BADegPer', 'AdvDegPer'], dtype='object')\n",
      "HSGradPer    object\n",
      "BADegPer     object\n",
      "AdvDegPer    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# We want to use the column *State* as index. Lets's run some checks first.\n",
    "# Check that there are no extraneous values in the column State. If you find some, clean them.\n",
    "print(df.index)\n",
    "print(df.columns)\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for duplicate values\n",
    "if df['State'].duplicated().any():\n",
    "    print(\"Duplicate values found in the State column:\")\n",
    "    print(df[df['State'].duplicated(keep=False)].sort_values(by='State'))\n",
    "else:\n",
    "    print(\"No duplicate values found in the State column.\")\n",
    "\n",
    "# Check for Missing or NaN Values\n",
    "if df['State'].isna().any():\n",
    "    print(\"NaN values found in the State column:\")\n",
    "    print(df[df['State'].isna()])\n",
    "else:\n",
    "    print(\"No NaN values found in the State column.\")\n",
    "\n",
    "non_strings = df[df['State'].apply(lambda x: not isinstance(x, str))]\n",
    "if not non_strings.empty:\n",
    "    print(\"Non-string values found in the State column:\")\n",
    "    print(non_strings)\n",
    "else:\n",
    "    print(\"All values in the State column are strings.\")\n",
    "\n",
    "# Set the index to 'State'\n",
    "df.set_index('State', inplace=True)\n",
    "\n",
    "print(df.index)\n",
    "print(df.columns)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a list comprehension to return all states in the column States that have extraneous characters. You can apply the Python method [isalpha](https://docs.python.org/3/library/stdtypes.html) to a string to check whether all characters in it are alphabetic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:59:32.019842Z",
     "start_time": "2023-09-05T20:59:31.904756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Montana', 'New_Hampshire', 'Minnesota', 'Wyoming', 'Alaska',\n",
      "       'North_Dakota', 'Vermont', 'Maine', 'Iowa', 'Utah', 'Wisconsin',\n",
      "       'Hawaii', 'South_Dakota', 'Colorado', 'Nebraska', 'Washington',\n",
      "       'Kansas', 'District_of_Columbia', 'Massachusetts', 'Idaho', 'Michigan',\n",
      "       'Connecticut', 'Oregon', 'Pennsylvania', 'Maryland', 'Ohio', 'Delaware',\n",
      "       'Missouri', 'New_Jersey', 'Virginia', 'Illinois', 'Indiana', 'Florida',\n",
      "       'Oklahoma', 'Rhode_Island', 'United_States', 'North_Carolina',\n",
      "       'South_Carolina', 'Tennessee', 'Georgia', 'New_York', 'West_Virginia',\n",
      "       'Nevada', 'Arkansas', 'Alabama', 'Kentucky', 'New_Mexico', 'Louisiana',\n",
      "       'Mississippi', 'Texas', 'California', 'Arizona'],\n",
      "      dtype='object', name='State')\n",
      "Are index values unique? True\n"
     ]
    }
   ],
   "source": [
    "# In the column State replace the whitespaces with underscores\n",
    "\n",
    "# Strip leading and trailing whitespaces from the index\n",
    "df.index = df.index.str.strip()\n",
    "\n",
    "#Replace all remaining whitespaces with underscores\n",
    "df.index = df.index.str.replace(' ', '_')\n",
    "\n",
    "# Show the modified index\n",
    "print(df.index)\n",
    "\n",
    "# Check if index values are unique\n",
    "are_indexes_unique = df.index.is_unique\n",
    "\n",
    "# Print the result\n",
    "print(\"Are index values unique?\", are_indexes_unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the Series method [str.replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html?highlight=str%20replace#pandas.Series.str.replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:00:01.920640Z",
     "start_time": "2023-09-05T21:00:01.909918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     HSGradPer BADegPer AdvDegPer\n",
      "State                                            \n",
      "Montana                  93.0%    30.7%     10.1%\n",
      "New_Hampshire            92.8%    36.0%     13.8%\n",
      "Minnesota                92.8%    34.8%     11.8%\n",
      "Wyoming                  92.8%    26.7%      9.3%\n",
      "Alaska                   92.4%    29.0%     10.4%\n",
      "North_Dakota             92.3%    28.9%      7.8%\n",
      "Vermont                  92.3%    36.8%     15.0%\n",
      "Maine                    92.1%    30.3%     10.9%\n",
      "Iowa                     91.8%    27.7%      9.0%\n",
      "Utah                     91.8%    32.5%     11.0%\n",
      "Wisconsin                91.7%    29.0%      9.9%\n",
      "Hawaii                   91.6%    32.0%     10.8%\n",
      "South_Dakota             91.4%    27.8%      8.3%\n",
      "Colorado                 91.1%    39.4%     14.6%\n",
      "Nebraska                 90.9%    30.6%     10.2%\n",
      "Washington               90.8%    34.5%     12.7%\n",
      "Kansas                   90.5%    32.3%     11.7%\n",
      "District_of_Columbia     90.3%    56.6%     32.8%\n",
      "Massachusetts            90.3%    42.1%     18.7%\n",
      "Idaho                    90.2%    26.8%      8.5%\n",
      "Michigan                 90.2%    28.1%     11.0%\n",
      "Connecticut              90.2%    38.4%     17.0%\n",
      "Oregon                   76.7%    32.3%     12.2%\n",
      "Pennsylvania             89.9%    30.1%     11.8%\n",
      "Maryland                 89.8%    39.0%     18.0%\n",
      "Ohio                     89.8%    27.2%     10.2%\n",
      "Delaware                 89.3%    31.0%     12.9%\n",
      "Missouri                 89.2%    28.2%     10.7%\n",
      "New_Jersey               89.2%    38.1%     14.7%\n",
      "Virginia                 89.0%    37.6%     16.1%\n",
      "Illinois                 88.6%    33.4%     13.0%\n",
      "Indiana                  88.3%    25.3%      9.2%\n",
      "Florida                  87.6%    28.5%     10.3%\n",
      "Oklahoma                 87.5%    24.8%      8.3%\n",
      "Rhode_Island             87.3%    33.0%     13.1%\n",
      "North_Carolina           86.9%    29.9%     10.6%\n",
      "South_Carolina           86.5%    27.0%      9.8%\n",
      "Tennessee                86.5%    26.1%      9.6%\n",
      "Georgia                  86.3%    29.9%     11.4%\n",
      "New_York                 86.1%    35.3%     15.4%\n",
      "West_Virginia            85.9%    19.9%      7.9%\n",
      "Nevada                   85.8%    23.7%      8.1%\n",
      "Arkansas                 85.6%    22.0%      7.9%\n",
      "Alabama                  85.3%    24.5%      9.1%\n",
      "Kentucky                 85.2%    23.2%      9.6%\n",
      "New_Mexico               85.0%    26.9%     11.8%\n",
      "Louisiana                84.3%    23.4%      8.1%\n",
      "Mississippi              83.4%    21.3%      8.0%\n",
      "Texas                    82.8%    28.7%      9.9%\n",
      "California               82.5%    32.6%     12.2%\n",
      "Arizona                  82.1%    28.4%     10.7%\n"
     ]
    }
   ],
   "source": [
    "# Get rid of the summary row \"United_States\"\n",
    "\n",
    "# Remove the row with index 'United_States'\n",
    "# df.drop('United_States', inplace=True)\n",
    "df.drop('United_States', inplace=True, errors='ignore')\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the DataFrame method [drop](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:00:26.759116Z",
     "start_time": "2023-09-05T21:00:26.662112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is only one row for each state.\n"
     ]
    }
   ],
   "source": [
    "# Make a last check that there is only one row for each state\n",
    "# Count the number of unique index values (states)\n",
    "num_unique_states = df.index.nunique()\n",
    "\n",
    "# Count the total number of rows in the DataFrame\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "# Check if each state has only one corresponding row\n",
    "if num_unique_states == total_rows:\n",
    "    print(\"There is only one row for each state.\")\n",
    "else:\n",
    "    print(\"Some states appear more than once.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:00:37.906735Z",
     "start_time": "2023-09-05T21:00:37.876543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     HSGradPer BADegPer AdvDegPer\n",
      "State                                            \n",
      "Alabama                  85.3%    24.5%      9.1%\n",
      "Alaska                   92.4%    29.0%     10.4%\n",
      "Arizona                  82.1%    28.4%     10.7%\n",
      "Arkansas                 85.6%    22.0%      7.9%\n",
      "California               82.5%    32.6%     12.2%\n",
      "Colorado                 91.1%    39.4%     14.6%\n",
      "Connecticut              90.2%    38.4%     17.0%\n",
      "Delaware                 89.3%    31.0%     12.9%\n",
      "District_of_Columbia     90.3%    56.6%     32.8%\n",
      "Florida                  87.6%    28.5%     10.3%\n",
      "Georgia                  86.3%    29.9%     11.4%\n",
      "Hawaii                   91.6%    32.0%     10.8%\n",
      "Idaho                    90.2%    26.8%      8.5%\n",
      "Illinois                 88.6%    33.4%     13.0%\n",
      "Indiana                  88.3%    25.3%      9.2%\n",
      "Iowa                     91.8%    27.7%      9.0%\n",
      "Kansas                   90.5%    32.3%     11.7%\n",
      "Kentucky                 85.2%    23.2%      9.6%\n",
      "Louisiana                84.3%    23.4%      8.1%\n",
      "Maine                    92.1%    30.3%     10.9%\n",
      "Maryland                 89.8%    39.0%     18.0%\n",
      "Massachusetts            90.3%    42.1%     18.7%\n",
      "Michigan                 90.2%    28.1%     11.0%\n",
      "Minnesota                92.8%    34.8%     11.8%\n",
      "Mississippi              83.4%    21.3%      8.0%\n",
      "Missouri                 89.2%    28.2%     10.7%\n",
      "Montana                  93.0%    30.7%     10.1%\n",
      "Nebraska                 90.9%    30.6%     10.2%\n",
      "Nevada                   85.8%    23.7%      8.1%\n",
      "New_Hampshire            92.8%    36.0%     13.8%\n",
      "New_Jersey               89.2%    38.1%     14.7%\n",
      "New_Mexico               85.0%    26.9%     11.8%\n",
      "New_York                 86.1%    35.3%     15.4%\n",
      "North_Carolina           86.9%    29.9%     10.6%\n",
      "North_Dakota             92.3%    28.9%      7.8%\n",
      "Ohio                     89.8%    27.2%     10.2%\n",
      "Oklahoma                 87.5%    24.8%      8.3%\n",
      "Oregon                   76.7%    32.3%     12.2%\n",
      "Pennsylvania             89.9%    30.1%     11.8%\n",
      "Rhode_Island             87.3%    33.0%     13.1%\n",
      "South_Carolina           86.5%    27.0%      9.8%\n",
      "South_Dakota             91.4%    27.8%      8.3%\n",
      "Tennessee                86.5%    26.1%      9.6%\n",
      "Texas                    82.8%    28.7%      9.9%\n",
      "Utah                     91.8%    32.5%     11.0%\n",
      "Vermont                  92.3%    36.8%     15.0%\n",
      "Virginia                 89.0%    37.6%     16.1%\n",
      "Washington               90.8%    34.5%     12.7%\n",
      "West_Virginia            85.9%    19.9%      7.9%\n",
      "Wisconsin                91.7%    29.0%      9.9%\n",
      "Wyoming                  92.8%    26.7%      9.3%\n"
     ]
    }
   ],
   "source": [
    "# Set the column State as the index\n",
    "# Order the dataframe according to the index\n",
    "# Inspect the dataframe\n",
    "\n",
    "# Set the 'State' column as the index\n",
    "# df.set_index('State', inplace=True)\n",
    "\n",
    "# Sort the DataFrame by the index (State)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "# Show the first few rows of the DataFrame to inspect the data\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there is only one row for each state and then set *State* as the index of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:00:57.749305Z",
     "start_time": "2023-09-05T21:00:57.712806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSGradPer    object\n",
      "BADegPer     object\n",
      "AdvDegPer    object\n",
      "dtype: object\n",
      "['85.3%' '92.4%' '82.1%' '85.6%' '82.5%' '91.1%' '90.2%' '89.3%' '90.3%'\n",
      " '87.6%' '86.3%' '91.6%' '88.6%' '88.3%' '91.8%' '90.5%' '85.2%' '84.3%'\n",
      " '92.1%' '89.8%' '92.8%' '83.4%' '89.2%' '93.0%' '90.9%' '85.8%' '85.0%'\n",
      " '86.1%' '86.9%' '92.3%' '87.5%' '76.7%' '89.9%' '87.3%' '86.5%' '91.4%'\n",
      " '82.8%' '89.0%' '90.8%' '85.9%' '91.7%']\n",
      "['24.5%' '29.0%' '28.4%' '22.0%' '32.6%' '39.4%' '38.4%' '31.0%' '56.6%'\n",
      " '28.5%' '29.9%' '32.0%' '26.8%' '33.4%' '25.3%' '27.7%' '32.3%' '23.2%'\n",
      " '23.4%' '30.3%' '39.0%' '42.1%' '28.1%' '34.8%' '21.3%' '28.2%' '30.7%'\n",
      " '30.6%' '23.7%' '36.0%' '38.1%' '26.9%' '35.3%' '28.9%' '27.2%' '24.8%'\n",
      " '30.1%' '33.0%' '27.0%' '27.8%' '26.1%' '28.7%' '32.5%' '36.8%' '37.6%'\n",
      " '34.5%' '19.9%' '26.7%']\n",
      "['9.1%' '10.4%' '10.7%' '7.9%' '12.2%' '14.6%' '17.0%' '12.9%' '32.8%'\n",
      " '10.3%' '11.4%' '10.8%' '8.5%' '13.0%' '9.2%' '9.0%' '11.7%' '9.6%'\n",
      " '8.1%' '10.9%' '18.0%' '18.7%' '11.0%' '11.8%' '8.0%' '10.1%' '10.2%'\n",
      " '13.8%' '14.7%' '15.4%' '10.6%' '7.8%' '8.3%' '13.1%' '9.8%' '9.9%'\n",
      " '15.0%' '16.1%' '12.7%' '9.3%']\n",
      "HSGradPer    0\n",
      "BADegPer     0\n",
      "AdvDegPer    0\n",
      "dtype: int64\n",
      "HSGradPer    float64\n",
      "BADegPer     float64\n",
      "AdvDegPer    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check that all the numerical column were loaded as a number\n",
    "# If that's not the case, find out why, correct it, and cast the columns as numbers\n",
    "print(df.dtypes)\n",
    "\n",
    "print(df['HSGradPer'].unique())\n",
    "print(df['BADegPer'].unique())\n",
    "print(df['AdvDegPer'].unique())\n",
    "\n",
    "df['HSGradPer'] = df['HSGradPer'].str.replace('%', '')\n",
    "df['BADegPer'] = df['BADegPer'].str.replace('%', '')\n",
    "df['AdvDegPer'] = df['AdvDegPer'].str.replace('%', '')\n",
    "\n",
    "df['HSGradPer'] = pd.to_numeric(df['HSGradPer'], errors='coerce')\n",
    "df['BADegPer'] = pd.to_numeric(df['BADegPer'], errors='coerce')\n",
    "df['AdvDegPer'] = pd.to_numeric(df['AdvDegPer'], errors='coerce')\n",
    "\n",
    "print(df.isna().sum())\n",
    "\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:01:34.464491Z",
     "start_time": "2023-09-05T21:01:34.452260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      HSGradPer  BADegPer  AdvDegPer\n",
      "State                                               \n",
      "Alabama                    85.3      24.5        9.1\n",
      "Alaska                     92.4      29.0       10.4\n",
      "Arizona                    82.1      28.4       10.7\n",
      "Arkansas                   85.6      22.0        7.9\n",
      "California                 82.5      32.6       12.2\n",
      "Colorado                   91.1      39.4       14.6\n",
      "Connecticut                90.2      38.4       17.0\n",
      "Delaware                   89.3      31.0       12.9\n",
      "District_of_Columbia       90.3      56.6       32.8\n",
      "Florida                    87.6      28.5       10.3\n",
      "Georgia                    86.3      29.9       11.4\n",
      "Hawaii                     91.6      32.0       10.8\n",
      "Idaho                      90.2      26.8        8.5\n",
      "Illinois                   88.6      33.4       13.0\n",
      "Indiana                    88.3      25.3        9.2\n",
      "Iowa                       91.8      27.7        9.0\n",
      "Kansas                     90.5      32.3       11.7\n",
      "Kentucky                   85.2      23.2        9.6\n",
      "Louisiana                  84.3      23.4        8.1\n",
      "Maine                      92.1      30.3       10.9\n",
      "Maryland                   89.8      39.0       18.0\n",
      "Massachusetts              90.3      42.1       18.7\n",
      "Michigan                   90.2      28.1       11.0\n",
      "Minnesota                  92.8      34.8       11.8\n",
      "Mississippi                83.4      21.3        8.0\n",
      "Missouri                   89.2      28.2       10.7\n",
      "Montana                    93.0      30.7       10.1\n",
      "Nebraska                   90.9      30.6       10.2\n",
      "Nevada                     85.8      23.7        8.1\n",
      "New_Hampshire              92.8      36.0       13.8\n",
      "New_Jersey                 89.2      38.1       14.7\n",
      "New_Mexico                 85.0      26.9       11.8\n",
      "New_York                   86.1      35.3       15.4\n",
      "North_Carolina             86.9      29.9       10.6\n",
      "North_Dakota               92.3      28.9        7.8\n",
      "Ohio                       89.8      27.2       10.2\n",
      "Oklahoma                   87.5      24.8        8.3\n",
      "Oregon                     76.7      32.3       12.2\n",
      "Pennsylvania               89.9      30.1       11.8\n",
      "Rhode_Island               87.3      33.0       13.1\n",
      "South_Carolina             86.5      27.0        9.8\n",
      "South_Dakota               91.4      27.8        8.3\n",
      "Tennessee                  86.5      26.1        9.6\n",
      "Texas                      82.8      28.7        9.9\n",
      "Utah                       91.8      32.5       11.0\n",
      "Vermont                    92.3      36.8       15.0\n",
      "Virginia                   89.0      37.6       16.1\n",
      "Washington                 90.8      34.5       12.7\n",
      "West_Virginia              85.9      19.9        7.9\n",
      "Wisconsin                  91.7      29.0        9.9\n",
      "Wyoming                    92.8      26.7        9.3\n"
     ]
    }
   ],
   "source": [
    "# Make a last inspection of the dataframe edu\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Life Expectancy: \"life_expectancy.csv\"\n",
    "The file contains the following columns  \n",
    "\n",
    "```\n",
    "Column        | Description\n",
    "--------------| --------------------------------\n",
    "State         | name of the state  \n",
    "LifeExp2018   | life expectancy (2017)   \n",
    "LifeExp2010   | life expectancy (2010)\n",
    "MaleLifeExp   | male life expectancy\n",
    "FemLifeExp    | female life expectancy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T21:38:34.379636Z",
     "start_time": "2023-09-06T21:38:34.367880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        State LifeExp2018  LifeExp2010  MaleLifeExp  \\\n",
      "0                      Hawaii        82.3         81.4         79.3   \n",
      "1                  California        81.6         80.6         79.4   \n",
      "2                 Puerto Rico        81.3         78.7         77.6   \n",
      "3                    New York        81.3         80.3         79.0   \n",
      "4         U.S. Virgin Islands        81.2         79.2         76.3   \n",
      "5                   Minnesota        81.0         80.8         79.0   \n",
      "6                 Connecticut        80.9         80.7         78.7   \n",
      "7                        Guam        80.7         78.2         77.6   \n",
      "8                    Colorado        80.5         80.1         78.5   \n",
      "9               Massachusetts        80.5         80.5         78.2   \n",
      "10                 Washington        80.4         80.1         78.4   \n",
      "11                 New Jersey        80.4         80.0         78.2   \n",
      "12                    Florida        80.0         79.0         77.3   \n",
      "13                    Arizona        79.9         79.3         77.5   \n",
      "14               Rhode Island        79.9         79.5         77.7   \n",
      "15               North Dakota        79.9         79.7         77.6   \n",
      "16                       Utah        79.9         79.8         78.2   \n",
      "17                     Oregon        79.8         79.5         77.8   \n",
      "18                    Vermont        79.7         80.1         77.8   \n",
      "19                   Nebraska        79.6         79.7         77.4   \n",
      "20                   Virginia        79.5         79.1         77.4   \n",
      "21              New Hampshire        79.5         80.3         77.5   \n",
      "22                       Iowa        79.4         79.6         77.2   \n",
      "23                  Wisconsin        79.4         79.6         77.3   \n",
      "24                   Illinois        79.3         79.0         77.0   \n",
      "25                      Idaho        79.3         79.4         77.4   \n",
      "26                      Texas        79.1         78.4         76.8   \n",
      "27                   Maryland        79.1         79.0         76.7   \n",
      "28               South Dakota        79.1         79.3         76.7   \n",
      "29                    Wyoming        79.0         78.1         77.1   \n",
      "30                     Alaska        78.8         78.0         76.7   \n",
      "31                    Montana        78.8         78.5         76.8   \n",
      "32              United States    78.7[17]         78.7         76.2   \n",
      "33                      Maine        78.7         79.1         76.6   \n",
      "34       District of Columbia        78.6         76.5         75.7   \n",
      "35                     Nevada        78.5         77.8         76.1   \n",
      "36                     Kansas        78.5         78.6         76.3   \n",
      "37                   Delaware        78.4         78.3         76.2   \n",
      "38               Pennsylvania        78.3         78.5         75.8   \n",
      "39                 New Mexico        78.1         78.2         75.3   \n",
      "40             North Carolina        78.0         77.8         75.5   \n",
      "41                   Michigan        78.0         78.0         75.7   \n",
      "42                    Georgia        77.8         77.3         75.4   \n",
      "43                   Missouri        77.3         77.4         74.9   \n",
      "44             South Carolina        77.0         76.8         74.4   \n",
      "45                    Indiana        77.0         77.5         74.6   \n",
      "46                       Ohio        76.9         77.7         74.6   \n",
      "47   Northern Mariana Islands        76.4         76.9         73.6   \n",
      "48                  Louisiana        76.1         75.8         73.4   \n",
      "49                   Oklahoma        76.0         75.7         73.7   \n",
      "50                  Tennessee        76.0         76.2         73.3   \n",
      "51                   Arkansas        75.9         76.0         73.1   \n",
      "52                    Alabama        75.4         75.4         72.6   \n",
      "53                   Kentucky        75.4         75.9         72.8   \n",
      "54                Mississippi        74.9         74.8         71.9   \n",
      "55             American Samoa        74.8         74.0         73.0   \n",
      "56              West Virginia        74.8         75.5         72.4   \n",
      "\n",
      "    FemLifeExp  \n",
      "0         85.3  \n",
      "1         83.8  \n",
      "2         84.7  \n",
      "3         83.4  \n",
      "4         85.6  \n",
      "5         83.0  \n",
      "6         83.0  \n",
      "7         83.8  \n",
      "8         82.5  \n",
      "9         82.6  \n",
      "10        82.4  \n",
      "11        82.5  \n",
      "12        82.6  \n",
      "13        82.3  \n",
      "14        82.1  \n",
      "15        82.5  \n",
      "16        81.6  \n",
      "17        81.9  \n",
      "18        81.7  \n",
      "19        81.7  \n",
      "20        81.5  \n",
      "21        81.4  \n",
      "22        81.6  \n",
      "23        81.5  \n",
      "24        81.6  \n",
      "25        81.2  \n",
      "26        81.5  \n",
      "27        81.4  \n",
      "28        81.6  \n",
      "29        81.1  \n",
      "30        81.2  \n",
      "31        81.0  \n",
      "32        81.2  \n",
      "33        81.0  \n",
      "34        81.3  \n",
      "35        81.0  \n",
      "36        80.7  \n",
      "37        80.6  \n",
      "38        80.6  \n",
      "39        81.0  \n",
      "40        80.3  \n",
      "41        80.2  \n",
      "42        80.0  \n",
      "43        79.8  \n",
      "44        79.6  \n",
      "45        79.3  \n",
      "46        79.2  \n",
      "47        79.3  \n",
      "48        79.0  \n",
      "49        78.4  \n",
      "50        78.6  \n",
      "51        78.6  \n",
      "52        78.1  \n",
      "53        77.9  \n",
      "54        78.0  \n",
      "55        77.0  \n",
      "56        77.4  \n",
      "Index(['State', 'LifeExp2018', 'LifeExp2010', 'MaleLifeExp', 'FemLifeExp'], dtype='object')\n",
      "Column 'State' not found in DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# load the file life_expectancy.csv and make a first inspection\n",
    "\n",
    "life_exp_csv_name = 'work/csv/life_expectancy.csv'\n",
    "life_exp = pd.read_csv('%s' % life_exp_csv_name, delimiter=';')\n",
    "\n",
    "print(life_exp)\n",
    "print(life_exp.columns)\n",
    "if 'State' in df.columns:\n",
    "    df['State'] = df['State'].str.strip()\n",
    "else:\n",
    "    print(\"Column 'State' not found in DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T21:38:14.696322Z",
     "start_time": "2023-09-06T21:38:14.690749Z"
    }
   },
   "outputs": [],
   "source": [
    "# We'll follow the same steps for the file life_expectancy\n",
    "# Since you will have to repeat these steps for the other files, we are going to define a function to clean a dataset\n",
    "def set_state_as_index(df):\n",
    "    # Clean the column 'State', eliminating extraneous whitespaces at both ends\n",
    "    df['State'] = df['State'].str.strip()\n",
    "\n",
    "    # Replace the middle whitespaces with underscores\n",
    "    df['State'] = df['State'].str.replace(' ', '_')\n",
    "\n",
    "    # Check that there are no duplicates in the column 'State'\n",
    "    if df['State'].duplicated().any():\n",
    "        print(\"Duplicate values found in the State column:\")\n",
    "        print(df[df['State'].duplicated(keep=False)].sort_values(by='State'))\n",
    "        # Additional steps to handle duplicates would go here\n",
    "    else:\n",
    "        print(\"No duplicate values found in the State column.\")\n",
    "    \n",
    "    # Set the 'State' column as the index of the DataFrame and sort by the index\n",
    "    df.set_index('State', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    # if there is a summary row \"United States\", drop it\n",
    "    # If there is a summary row \"United_States\", drop it\n",
    "    if \"United_States\" in df.index:\n",
    "        df.drop(\"United_States\", inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T21:38:53.985426Z",
     "start_time": "2023-09-06T21:38:53.891268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate values found in the State column.\n"
     ]
    }
   ],
   "source": [
    "# Run the function set_state_as_index on life_exp\n",
    "life_exp = set_state_as_index(life_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T21:38:56.416700Z",
     "start_time": "2023-09-06T21:38:56.410240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         LifeExp2018  LifeExp2010  MaleLifeExp  FemLifeExp\n",
      "State                                                                     \n",
      "Alabama                         75.4         75.4         72.6        78.1\n",
      "Alaska                          78.8         78.0         76.7        81.2\n",
      "American_Samoa                  74.8         74.0         73.0        77.0\n",
      "Arizona                         79.9         79.3         77.5        82.3\n",
      "Arkansas                        75.9         76.0         73.1        78.6\n",
      "California                      81.6         80.6         79.4        83.8\n",
      "Colorado                        80.5         80.1         78.5        82.5\n",
      "Connecticut                     80.9         80.7         78.7        83.0\n",
      "Delaware                        78.4         78.3         76.2        80.6\n",
      "District_of_Columbia            78.6         76.5         75.7        81.3\n",
      "Florida                         80.0         79.0         77.3        82.6\n",
      "Georgia                         77.8         77.3         75.4        80.0\n",
      "Guam                            80.7         78.2         77.6        83.8\n",
      "Hawaii                          82.3         81.4         79.3        85.3\n",
      "Idaho                           79.3         79.4         77.4        81.2\n",
      "Illinois                        79.3         79.0         77.0        81.6\n",
      "Indiana                         77.0         77.5         74.6        79.3\n",
      "Iowa                            79.4         79.6         77.2        81.6\n",
      "Kansas                          78.5         78.6         76.3        80.7\n",
      "Kentucky                        75.4         75.9         72.8        77.9\n",
      "Louisiana                       76.1         75.8         73.4        79.0\n",
      "Maine                           78.7         79.1         76.6        81.0\n",
      "Maryland                        79.1         79.0         76.7        81.4\n",
      "Massachusetts                   80.5         80.5         78.2        82.6\n",
      "Michigan                        78.0         78.0         75.7        80.2\n",
      "Minnesota                       81.0         80.8         79.0        83.0\n",
      "Mississippi                     74.9         74.8         71.9        78.0\n",
      "Missouri                        77.3         77.4         74.9        79.8\n",
      "Montana                         78.8         78.5         76.8        81.0\n",
      "Nebraska                        79.6         79.7         77.4        81.7\n",
      "Nevada                          78.5         77.8         76.1        81.0\n",
      "New_Hampshire                   79.5         80.3         77.5        81.4\n",
      "New_Jersey                      80.4         80.0         78.2        82.5\n",
      "New_Mexico                      78.1         78.2         75.3        81.0\n",
      "New_York                        81.3         80.3         79.0        83.4\n",
      "North_Carolina                  78.0         77.8         75.5        80.3\n",
      "North_Dakota                    79.9         79.7         77.6        82.5\n",
      "Northern_Mariana_Islands        76.4         76.9         73.6        79.3\n",
      "Ohio                            76.9         77.7         74.6        79.2\n",
      "Oklahoma                        76.0         75.7         73.7        78.4\n",
      "Oregon                          79.8         79.5         77.8        81.9\n",
      "Pennsylvania                    78.3         78.5         75.8        80.6\n",
      "Puerto_Rico                     81.3         78.7         77.6        84.7\n",
      "Rhode_Island                    79.9         79.5         77.7        82.1\n",
      "South_Carolina                  77.0         76.8         74.4        79.6\n",
      "South_Dakota                    79.1         79.3         76.7        81.6\n",
      "Tennessee                       76.0         76.2         73.3        78.6\n",
      "Texas                           79.1         78.4         76.8        81.5\n",
      "U.S._Virgin_Islands             81.2         79.2         76.3        85.6\n",
      "Utah                            79.9         79.8         78.2        81.6\n",
      "Vermont                         79.7         80.1         77.8        81.7\n",
      "Virginia                        79.5         79.1         77.4        81.5\n",
      "Washington                      80.4         80.1         78.4        82.4\n",
      "West_Virginia                   74.8         75.5         72.4        77.4\n",
      "Wisconsin                       79.4         79.6         77.3        81.5\n",
      "Wyoming                         79.0         78.1         77.1        81.1\n"
     ]
    }
   ],
   "source": [
    "# inspect the dataframe\n",
    "print(life_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets's check which numeric columns contain something else than digits or a dot.   \n",
    "We are going to use regular expressions to check if the elements of the dataframe contain numbers (digits with or without a dot).  \n",
    "If you want to review regular expression, see the link we provided in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T22:04:37.024098Z",
     "start_time": "2023-09-06T22:04:37.019474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean DataFrame:\n",
      "                          LifeExp2018  LifeExp2010  MaleLifeExp  FemLifeExp\n",
      "State                                                                      \n",
      "Alabama                          True         True         True        True\n",
      "Alaska                           True         True         True        True\n",
      "American_Samoa                   True         True         True        True\n",
      "Arizona                          True         True         True        True\n",
      "Arkansas                         True         True         True        True\n",
      "California                       True         True         True        True\n",
      "Colorado                         True         True         True        True\n",
      "Connecticut                      True         True         True        True\n",
      "Delaware                         True         True         True        True\n",
      "District_of_Columbia             True         True         True        True\n",
      "Florida                          True         True         True        True\n",
      "Georgia                          True         True         True        True\n",
      "Guam                             True         True         True        True\n",
      "Hawaii                           True         True         True        True\n",
      "Idaho                            True         True         True        True\n",
      "Illinois                         True         True         True        True\n",
      "Indiana                          True         True         True        True\n",
      "Iowa                             True         True         True        True\n",
      "Kansas                           True         True         True        True\n",
      "Kentucky                         True         True         True        True\n",
      "Louisiana                        True         True         True        True\n",
      "Maine                            True         True         True        True\n",
      "Maryland                         True         True         True        True\n",
      "Massachusetts                    True         True         True        True\n",
      "Michigan                         True         True         True        True\n",
      "Minnesota                        True         True         True        True\n",
      "Mississippi                      True         True         True        True\n",
      "Missouri                         True         True         True        True\n",
      "Montana                          True         True         True        True\n",
      "Nebraska                         True         True         True        True\n",
      "Nevada                           True         True         True        True\n",
      "New_Hampshire                    True         True         True        True\n",
      "New_Jersey                       True         True         True        True\n",
      "New_Mexico                       True         True         True        True\n",
      "New_York                         True         True         True        True\n",
      "North_Carolina                   True         True         True        True\n",
      "North_Dakota                     True         True         True        True\n",
      "Northern_Mariana_Islands         True         True         True        True\n",
      "Ohio                             True         True         True        True\n",
      "Oklahoma                         True         True         True        True\n",
      "Oregon                           True         True         True        True\n",
      "Pennsylvania                     True         True         True        True\n",
      "Puerto_Rico                      True         True         True        True\n",
      "Rhode_Island                     True         True         True        True\n",
      "South_Carolina                   True         True         True        True\n",
      "South_Dakota                     True         True         True        True\n",
      "Tennessee                        True         True         True        True\n",
      "Texas                            True         True         True        True\n",
      "U.S._Virgin_Islands              True         True         True        True\n",
      "Utah                             True         True         True        True\n",
      "Vermont                          True         True         True        True\n",
      "Virginia                         True         True         True        True\n",
      "Washington                       True         True         True        True\n",
      "West_Virginia                    True         True         True        True\n",
      "Wisconsin                        True         True         True        True\n",
      "Wyoming                          True         True         True        True\n",
      "\n",
      "Rows containing at least one value that's not a number:\n",
      "Empty DataFrame\n",
      "Columns: [LifeExp2018, LifeExp2010, MaleLifeExp, FemLifeExp]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# define a function that uses regular expresions to check if a string contains only digits with or without a dot\n",
    "import re\n",
    "def check_digit_or_dot(x):\n",
    "    if pd.isna(x):  # Skip NaN values\n",
    "        return False\n",
    "    pattern = r'^\\d+(\\.\\d+)?$'  # This regular expression matches digits with or without a dot\n",
    "    return bool(re.match(pattern, str(x)))\n",
    "\n",
    "# create a boolean dataframe that is the result of applying the function check_digit_or_dot to all the elements of life_exp\n",
    "bool_life_exp = life_exp.applymap(check_digit_or_dot)\n",
    "\n",
    "# inspect the rows of the boolean dataframe to see if there are any False values\n",
    "print(\"Boolean DataFrame:\")\n",
    "print(bool_life_exp)\n",
    "\n",
    "# Print the rows of df where there is at least one value that's not a number\n",
    "print(\"\\nRows containing at least one value that's not a number:\")\n",
    "print(life_exp[~bool_life_exp.all(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T22:07:31.789508Z",
     "start_time": "2023-09-06T22:07:31.784494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LifeExp2018    float64\n",
      "LifeExp2010    float64\n",
      "MaleLifeExp    float64\n",
      "FemLifeExp     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# coerce the columns to be numeric\n",
    "for col in life_exp.columns:\n",
    "    life_exp[col] = pd.to_numeric(life_exp[col], errors='raise')\n",
    "\n",
    "# check if all the columns are numeric\n",
    "print(life_exp.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T22:07:41.290371Z",
     "start_time": "2023-09-06T22:07:41.247609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          LifeExp2018  LifeExp2010  MaleLifeExp  FemLifeExp\n",
      "State                                                                      \n",
      "Alabama                          75.4         75.4         72.6        78.1\n",
      "Alaska                           78.8         78.0         76.7        81.2\n",
      "American_Samoa                   74.8         74.0         73.0        77.0\n",
      "Arizona                          79.9         79.3         77.5        82.3\n",
      "Arkansas                         75.9         76.0         73.1        78.6\n",
      "California                       81.6         80.6         79.4        83.8\n",
      "Colorado                         80.5         80.1         78.5        82.5\n",
      "Connecticut                      80.9         80.7         78.7        83.0\n",
      "Delaware                         78.4         78.3         76.2        80.6\n",
      "District_of_Columbia             78.6         76.5         75.7        81.3\n",
      "Florida                          80.0         79.0         77.3        82.6\n",
      "Georgia                          77.8         77.3         75.4        80.0\n",
      "Guam                             80.7         78.2         77.6        83.8\n",
      "Hawaii                           82.3         81.4         79.3        85.3\n",
      "Idaho                            79.3         79.4         77.4        81.2\n",
      "Illinois                         79.3         79.0         77.0        81.6\n",
      "Indiana                          77.0         77.5         74.6        79.3\n",
      "Iowa                             79.4         79.6         77.2        81.6\n",
      "Kansas                           78.5         78.6         76.3        80.7\n",
      "Kentucky                         75.4         75.9         72.8        77.9\n",
      "Louisiana                        76.1         75.8         73.4        79.0\n",
      "Maine                            78.7         79.1         76.6        81.0\n",
      "Maryland                         79.1         79.0         76.7        81.4\n",
      "Massachusetts                    80.5         80.5         78.2        82.6\n",
      "Michigan                         78.0         78.0         75.7        80.2\n",
      "Minnesota                        81.0         80.8         79.0        83.0\n",
      "Mississippi                      74.9         74.8         71.9        78.0\n",
      "Missouri                         77.3         77.4         74.9        79.8\n",
      "Montana                          78.8         78.5         76.8        81.0\n",
      "Nebraska                         79.6         79.7         77.4        81.7\n",
      "Nevada                           78.5         77.8         76.1        81.0\n",
      "New_Hampshire                    79.5         80.3         77.5        81.4\n",
      "New_Jersey                       80.4         80.0         78.2        82.5\n",
      "New_Mexico                       78.1         78.2         75.3        81.0\n",
      "New_York                         81.3         80.3         79.0        83.4\n",
      "North_Carolina                   78.0         77.8         75.5        80.3\n",
      "North_Dakota                     79.9         79.7         77.6        82.5\n",
      "Northern_Mariana_Islands         76.4         76.9         73.6        79.3\n",
      "Ohio                             76.9         77.7         74.6        79.2\n",
      "Oklahoma                         76.0         75.7         73.7        78.4\n",
      "Oregon                           79.8         79.5         77.8        81.9\n",
      "Pennsylvania                     78.3         78.5         75.8        80.6\n",
      "Puerto_Rico                      81.3         78.7         77.6        84.7\n",
      "Rhode_Island                     79.9         79.5         77.7        82.1\n",
      "South_Carolina                   77.0         76.8         74.4        79.6\n",
      "South_Dakota                     79.1         79.3         76.7        81.6\n",
      "Tennessee                        76.0         76.2         73.3        78.6\n",
      "Texas                            79.1         78.4         76.8        81.5\n",
      "U.S._Virgin_Islands              81.2         79.2         76.3        85.6\n",
      "Utah                             79.9         79.8         78.2        81.6\n",
      "Vermont                          79.7         80.1         77.8        81.7\n",
      "Virginia                         79.5         79.1         77.4        81.5\n",
      "Washington                       80.4         80.1         78.4        82.4\n",
      "West_Virginia                    74.8         75.5         72.4        77.4\n",
      "Wisconsin                        79.4         79.6         77.3        81.5\n",
      "Wyoming                          79.0         78.1         77.1        81.1\n"
     ]
    }
   ],
   "source": [
    "# inspect the whole dataframe life_exp to see if all is ok\n",
    "print(life_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime file: \"crime.csv\"\n",
    "\n",
    "The file contains the following columns:\n",
    "\n",
    "```\n",
    "Column   |  Description\n",
    "---------| --------------------------------\n",
    "1°       |  name of the state                              \n",
    "2°       |  population (total inhabitants) (2015)                   \n",
    "3°       |  murders and non-negligent manslaughter (total deaths) (2015)\n",
    "4°       |  murders (total deaths) (2015)\n",
    "5°       |  gun murders (total deaths) (2015)\n",
    "6°       |  gun ownership (%) (2013)\n",
    "7°       |  murders and non-negligent manslaughter rate (per 100,000) (2015)\n",
    "8°       |  murder rate (per 100,000) \n",
    "9°       |  gun murder rate (per 100,000)\n",
    "```\n",
    "\n",
    "\n",
    "Follow the same procedure as with the other files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area file: \"area.csv\"\n",
    "\n",
    "The file contains the following columns:    \n",
    "\n",
    "```\n",
    "Column    |  Description\n",
    "----------| --------------------------------\n",
    "State     |  name of the state                              \n",
    "TotalRank |  total area rank  \n",
    "TotalSqMi |  total area in SqMi\n",
    "TotalKmQ  |  total area in KmQ\n",
    "LandRank  |  land area rank\n",
    "LandSqMi  |  land area in SqMi \n",
    "LandKmQ   |  land area in KmQ\n",
    "LandPer   |  land area percentage \n",
    "WaterRank |  water area rank\n",
    "WaterSqMi |  water area in SqMi\n",
    "WaterKmQ  |  water area in KmQ\n",
    "WaterPer  |  water area percentage\n",
    "```\n",
    "\n",
    "Follow the same procedure as the other files\n",
    "Do not load the rank columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income file: \"income.xls\"\n",
    "\n",
    "For the file income we have an excel file: 'income.xlsx'. It contains the following columns:  \n",
    "\n",
    "```\n",
    "Column                                  |  Description    \n",
    "--------------------------------------- | --------------------------------   \n",
    "Rank                                    |  Rank for income in 2017   \n",
    "State                                   |  name of the State    \n",
    "Income2017                              |  median household  income in 2017   \n",
    "Income2016                              |  median household  income in 2016  \n",
    "...                                     |  ...  \n",
    "Income2007                              |  median household  income in 2007\n",
    "```\n",
    "\n",
    "Follow the same procedure as with the other files  \n",
    "Since this is an Excel file you'll need the Pandas function [read_excel](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)  \n",
    "Do not load the rank column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region file: \"region.txt\"\n",
    "The file 'region.txt' file contains the following columns:  \n",
    "\n",
    "```\n",
    "Column     |  Description\n",
    "---------- | --------------------------------\n",
    "Name      |  name of the state \n",
    "Abb        |  abbreviation of the name of the state\n",
    "Region     |  the region that each state belong to (Northeast, South, North Central, West)\n",
    "Division   |  state division (New England, Middle Atlantic, South Atlantic, East South Central, West South Central, East North Central, West North Central, Mountain, and Pacific)\n",
    "```\n",
    "\n",
    "Follow the same procedure as the other files  \n",
    "You can load it with the Pandas function [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)   \n",
    "Check what column separator was used.   \n",
    "Pay attention to the Division Column. There appear to be some inconsistencies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection Report\n",
    "\n",
    "We loaded four csv data files, an excel file, and a text file. The first five data files were acquired from the following internet sources (Wikipedia):   \n",
    "* edu.csv : [List of U.S. states and territories by educational attainment](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_educational_attainment)\n",
    "* crime.csv: [Gun violence in the United States by state](https://en.wikipedia.org/wiki/Gun_violence_in_the_United_States_by_state)\n",
    "* area.csv: [List of U.S. states and territories by area](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_area)\n",
    "* life_expectancy.csv: [List of U.S. states and territories by life expectancy](https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_life_expectancy)\n",
    "The income file was provided in Excel format  \n",
    "* income.xlsx: Household income in the United States (https://en.wikipedia.org/wiki/Household_income_in_the_United_States)\n",
    "The region text data file was obtained from R package ‘datasets’ (state.x77)  \n",
    "* region.txt \n",
    "\n",
    "#### Problems encountered:\n",
    "** TO TO **\n",
    "List the problems you encountered and the solution you took\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part , you'll examine the \"surface\" properties of the data. \n",
    "Check the number of rows of each dataframe.\n",
    "You can use the DataFrame property [shape](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html#pandas.DataFrame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description Report\n",
    "\n",
    "We acquired the following dataframes. All the dataframes have as index the State column.\n",
    "\n",
    "###### edu\n",
    "** TO DO **\n",
    "number of rows\n",
    "\n",
    "```\n",
    "Column    |  Type   | Description\n",
    "----------|---------|-------------------------\n",
    "State     |  object | name of the state         \n",
    "HSGradPer | float64 | % high school graduate or higher  \n",
    "BADegPer  | float64 | % bachelor degree or higher  \n",
    "AdvDegPer | float64 | % advanced degree or higher  \n",
    "```\n",
    "\n",
    "###### life_exp\n",
    "** TO DO **\n",
    "number of rows \n",
    "\n",
    "```\n",
    "Column      |  Type   | Description\n",
    "------------|---------|-------------------------\n",
    "State       |  object | name of the state         \n",
    "LifeExp2018 | float64 | life expectancy (2017)   \n",
    "LifeExp2010 | float64 | life expectancy (2010)   \n",
    "MaleLifeExp | float64 | male life expectancy  \n",
    "FemLifeExp  | float64 | female life expectancy\n",
    "```\n",
    "\n",
    "###### crime\n",
    "** TO DO **\n",
    "number of rows \n",
    "\n",
    "```\n",
    "Column       |  Type   | Description\n",
    "-------------|---------|-------------------------\n",
    "State        |  object | name of the state           \n",
    "PopTot       |   int64 | population (total inhabitants) (2015) \n",
    "MurderNMTot  |   int64 | murders and non-negligent manslaughter (total deaths) (2015)\n",
    "MurderTot    | float64 | murders (total deaths) (2015) \n",
    "GunMurderTot | float64 | gun murders (total deaths) (2015)\n",
    "GunOwnerPer  | float64 | gun ownership (%) (2013) \n",
    "MurderNMRate | float64 | murders and non-negligent manslaughter rate (per 100,000) (2015) \n",
    "MurderRate   | float64 | murder rate (per 100,000)\n",
    "GunMurderRate| float64 | gun murder rate (per 100,000)\n",
    "```\n",
    "\n",
    "###### area\n",
    "** TO DO **\n",
    "number of rows\n",
    "\n",
    "```\n",
    "Column    |  Type   | Description\n",
    "----------|---------|-------------------------\n",
    "State     |  object | name of the state           \n",
    "TotalSqMi | float64 |  total area in SqMi\n",
    "TotalKmQ  |   int64 |  total area in KmQ\n",
    "LandSqMi  | float64 |  land area in SqMi \n",
    "LandKmQ   |   int64 |  land area in KmQ\n",
    "LandPer   | float64 |  land area percentage \n",
    "WaterSqMi | float64 |  water area in SqMi\n",
    "WaterKmQ  |   int64 |  water area in KmQ\n",
    "WaterPer  | float64 |  water area percentage\n",
    "```\n",
    "\n",
    "###### income\n",
    "** TO DO **\n",
    "number of rows rows\n",
    "\n",
    "```\n",
    "Column     |  Type   | Description\n",
    "-----------|---------|-------------------------\n",
    "State      |  object | name of the state           \n",
    "Income2017 |   int64 | median household income in 2017\n",
    "Income2016 |   int64 | median household income in 2016\n",
    "Income2015 |   int64 | median household income in 2015\n",
    "Income2014 |   int64 | median household income in 2014\n",
    "Income2013 |   int64 | median household income in 2013\n",
    "Income2012 |   int64 | median household income in 2012\n",
    "Income2011 |   int64 | median household income in 2012\n",
    "Income2010 |   int64 | median household income in 2010\n",
    "Income2009 |   int64 | median household income in 2009\n",
    "Income2008 |   int64 | median household income in 2008\n",
    "Income2007 |   int64 | median household income in 2007\n",
    "```\n",
    "\n",
    "###### region\n",
    "** TO DO **\n",
    "number of row\n",
    "\n",
    "```\n",
    "Column     |  Type   | Description\n",
    "-----------|---------|-------------------------\n",
    "State      |  object | name of the state    \n",
    "Abb        |  object | abbreviation of the name of the state\n",
    "Region     |  object | the region that each state belongs to (Northeast, South, North Central, West)          \n",
    "Division   |  object | state divisions (New England, Middle Atlantic, South Atlantic, East South Central, West South Central, East North Central, West North Central, Mountain, and Pacific)           \n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you’ll examine if the data is complete. Check if you have all the cases you need (in this case, all the US states) and if there are missing values.\n",
    "\n",
    "In the U.S. there are 50 states, the federal district 'District of Columbia' and 5 inhabited territories: 'Puerto Rico', 'American Samoa', 'Guam', 'Northern Mariana Islands', and 'U.S. Virgin Islands’.\n",
    "\n",
    "Check if all the files you loaded contain the fifty states and if there are differences, investigate where these differences come from. You can use the index of the DataFrame region as a guide.\n",
    "\n",
    "Then check if there are missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a variable state_names with the states in the index of region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the other DataFrames, check if they contain a state that's not in state_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the dataframes have missing values.   \n",
    "You can use the DataFrame method [isnull](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.isnull.html?highlight=isnull#pandas.DataFrame.isnull)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Report\n",
    "\n",
    "In the U.S. there are fifty states, the federal district 'District of Columbia' and five inhabited territories: 'Puerto Rico', 'American Samoa', 'Guam', 'Northern Mariana Islands', and 'U.S. Virgin Islands'.\n",
    "\n",
    "** TO DO **       \n",
    "Explain your findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataframes for the next milestone.\n",
    "You can use the DataFrame method [to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html?highlight=to_csv#pandas.DataFrame.to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
